<meta charset="UTF-8">
<html>
<head>
	<link href='https://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
	<style>
		html {
    	font-family: 'Open Sans', sans-serif;
		}
		.center-div {
     margin: 0 auto;
     width: 640px;
	 	}
		.center-div-audio {
     margin: 0 auto;
     width: 320px;
	 	}
		.title {
			font-size: 40px;
		}
		.page-content {
    padding: 30px;
		}
</style>

	<title>Leveraging Online Audio Commons Content For Media Production Companion Website</title>
</head>
<body>

	<main class="page-content">

	<h1 class="title">Companion Website :: Routledge</h1>

	<p>This is the companion website of the book chapter "Leveraging Online Audio Commons Content For Media Production" (2018)
	by Anna Xambó, Frederic Font, György Fazekas, and Mathieu Barthet, which appears in Michael Filimowicz (ed.) <em>Foundations in Sound Design for Linear Media: an interdisciplinary approach</em>, Routledge.</p>

	<h1>Sound Examples</h1>

	<h2>AudioTexture</h2>

	<p>Developed by <a href="http://www.audiogaming.net/">AudioGaming</a>, AudioTexture is a plugin prototype for sound texture synthesis that leverages Audio Commons by bringing CC-licensed audio content into the DAW. The AudioTexture plugin lets users generate sonic textures from audio recordings from either online or local databases within a DAW environment, such as Logic Pro X, Ableton Live, or Reaper.</p>

	<h3>Example 1: Rain</h3>

	<p><em>Coming soon...</em></p>

	<h3>Example 2: Footsteps</h3>

	<p><em>Coming soon...</em></p>

	<h3>Example 3: Crowd</h3>

	<p><em>Coming soon...</em></p>

	<h3>Example 4: Reshuffling a bass line</h3>

	<p><em>Coming soon...</em></p>

	<h2>SampleSurfer</h2>

	<p>SampleSurfer has been developed by <a href="https://www.waves.com/">Waves Audio LTD</a> and is another plugin for the ACE that serves as an audio content search engine based on semantic metadata and musical features. The plugin is designed to integrate Audio Commons sound and music samples in a DAW-based environment by providing basic editing capabilities (e.g. fades, trims) to optimize the music production workflow.</p>

	<h3>Example 1: Edited vs. original sound</h3>

	<p><em>Coming soon...</em></p>

	<h3>Example 2: Musical composition with edited loops</h3>

	<p><em>Coming soon...</em></p>

	<h2>Soundscape Composition</h2>

	<p>We provide here examples of short soundscape compositions that have been created in the Fall of 2017 by students from the Sound Recording and Production Techniques module at Queen Mary University of London led by Mathieu Barthet. The soundscape themes were found by applying and adapting the participatory design technique described in Holmquist (2008). Students were invited to generate ideas across four categories: character, place/environment, situation/action, and mood. These ideas were combined randomly and formed the basis of soundscape themes after a reflection and simplification phase. Students were given the creative constraint of only using sounds sourced from Audio Commons or Apple Loops. They could edit and process the sounds in the DAW and were able to use AudioGaming’s AudioTexture plugin to generate novel sonic textures from Audio Commons audio content.</p>

	<h3>Example 1 - Submerged by Andrew Thompson</h3>

		<p>Abstract: The piece follows a short dream sequence of an individual drowning under immense pressure in their life. Sounds sourced from Freesound.org are arranged to create a compelling underwater soundscape that evolves into the distant memory of a jazz street performer. AudioTexture provides an evolving bed for the soundscape by blending large grains of an underwater boat recording.</p>

<div class="center-div">
	<iframe width="640" height="100" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/402139254&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true&visual=true"></iframe>
</div>

	<h3>Example 2 - “Space meal” by Andrea Guidi</h3>

	<p>Abstract: A metaphoric conversation between a woman doctor, a friend and smart devices happens during the soundscape. The doctor’s attention is overloaded both by notifications and by her friend's complaints while the listener's auditory experience is overloaded by the amplitude and presence of sounds from their meal (cutleries and chewing).</p>

	<p>The Freesound database was accessed within the Audio Texture VST. The research was conducted by using keywords related to the project constraints (character, place/environment, situation/action, and mood). The same VST was then used to time-scramble, pitch shift and filter the audio files to obtain a sound palette for the composition. Two main categories of musical events were achieved: audio textures and discrete events. The former was used to create the soundscape context while the latter to articulate a musical counterpoint. Finally, some editing, dynamic processing and stereo imaging strategies were applied to finalise the composition.</p>

<div class="center-div">
	<iframe width="640" height="100" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/402139245&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true&visual=true"></iframe>
</div>

	<h3>Example 3 - “A camper and his dog in France” by Caryl Jones</h3>

	<p>Abstract: The resources for this composition solely included recorded sounds from Freesound, the concatenative synthesis plugin AudioTexture to treat some of these sounds and audio samples from Apple Loops. The digital audio workstation (DAW) used was Logic and Audio Technica headphones for monitoring. The compositional approach was to create a figurative piece with an abstract, dream-like edge of a man walking his dog in France from a first person perspective. Sounds were divided into five categories for the arrangement and laid out in a linear way to tell a story from morning to evening with quick transitions between natural summer scenes. Sounds were arranged and mixed using trim, volume, pan automation, gain and EQ. The composition was mastered using a limiter to stop clipping.</p>

<div class="center-div">
	<iframe width="640" height="100" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/402139251&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true&visual=true"></iframe>
</div>

	<h3>References</h3>

	<ul><li>Holmquist, L. E. (2008). Bootlegging: multidisciplinary brainstorming with cut-ups. In: <em>Proceedings of the Tenth Anniversary Conference on Participatory Design 2008</em>. Indiana University, pp. 158-161.</li></ul>


	<h2>MIRLC (MIR and Live Coding)</h2>

	 <p>MIRLC (Xambó et al. 2018) is a library designed to repurpose audio samples from Freesound, which can also be applied to local databases, by providing human-like queries and real-time performance capabilities. The system is built within the SuperCollider environment by leveraging the Freesound API.
		<a href="https://www.audiocommons.org/2018/06/08/nime-2018-mirlc-fluidsound.html">The library was presented at the New Interfaces for Musical Expression conference</a> at Virginia Tech in 2018.</p>


		<h3>Example 1 - Demo</h3>
			<div class="center-div">
				<iframe src="https://player.vimeo.com/video/249968326" width="640" height="360" frameborder="0" allowfullscreen></iframe>
			</div>

		<h3>Example 2 - Music improvisation by Jack Armitage</h3>

		<p>Abstract: Being somewhat familiar with the Freesound database, I wanted to see if it could be used to create a shifting cinematic landscape by text-based search and sequencing alone. I chose four environments that I felt should have reasonable coverage in the database, and that would be sonically distinct; garden, street, city and airport. I came up with three or four search terms for each environment, checked that they returned at least one usable result, and improvised between them using a list of queries as a score. I did not feel in control of the output; the results were largely a surprise.</p>

		<div class="center-div-audio">
		<audio controls>
			<source src="http://crowdj.net/routledge/jack-mirlc.mp3" type="audio/mpeg">
				Your browser does not support the audio element.
		</audio>
	</div>

		<p>The following CC sounds were used in the piece: <a href="http://crowdj.net/routledge/jack-mirlc-credits.txt">http://crowdj.net/routledge/jack-mirlc-credits.txt</a>


		<h3>Example 3 - Music improvisation by Alo Allik</h3>

		<p>Abstract: The MIRLC library opens up new interesting opportunities for live coders who seek to augment their practices with access to Freesound content. This can be done very efficiently on-the-fly with MIRLC and often with an element of surprise to the performer which is frequently the desired behaviour of a system in the world of live coding. This experiment in improvisation makes use of four core samples searched by key words - rainstick, breaking glass, bullroarer and didgeridoo - with a certain sonic context in mind: rainstick for overall texture, breaking glass for punctuation, and the latter two for low frequency contrast. The rest of the sampled content was extracted with the similarity search functionality that allows the live coder to really explore the Freesound database in detail while being constantly surprised by the returned results and having to make compositional choices in response. The core samples were also subjected to further signal processing, including reverberation, playback rate changes and pitch shifting which, when applied simultaneously, create a different, more electronic-sounding sonic outcome. The aesthetic approach here was to gradually move from unprocessed samples to almost unrecognisable digital phasing of sounds. </p>

		<div class="center-div-audio">
		<audio controls>
  		<source src="http://crowdj.net/routledge/alo-mirlc.mp3" type="audio/mpeg">
				Your browser does not support the audio element.
		</audio>
	</div>

		<p>The following CC sounds were used in the piece: <a href="http://crowdj.net/routledge/alo-mirlc-credits.txt">http://crowdj.net/routledge/alo-mirlc-credits.txt</a>


		<h3>Example 4 - H2RI.03 by Anna Xambó (H2RI, pan y rosas 2018)</h3>

		<p><a href="http://www.panyrosasdiscos.net/2018/05/pan-y-rosas-release-h2ri-by-anna-xambo/">H2RI</a> is an instance of a generative album created by Anna Xambó in 2018.
			This track is an example of the 20 tracks of 1′ each that have been generated using her self-built tool MIRLC, a library for using music information retrieval techniques in live coding.
			A basic rule has shaped the audio sources of the album: to only use of short sounds from the crowd-sourced, online, sound database Freesound.
		</p>

		<div class="center-div">
		<iframe width="640" height="100" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/444932463&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true&visual=true"></iframe>
		</div>

		<p>The following CC sounds were used in the piece: <a href="http://www.panyrosasdiscos.net/anna-xambo-h2ri-credits/">http://www.panyrosasdiscos.net/anna-xambo-h2ri-credits/</a>

		<h3>References</h3>

		<ul><li>Xambó, A., Roma, G., Lerch, A., Barthet, M. and Fakekas, G. (2018). <a href="http://annaxambo.me/pub/Xambo_et_al_2018_Live_repurposing_of_sounds.pdf">Live repurposing of sounds: MIR explorations with personal and crowdsourced databases</a>. In: Proceedings of the International Conference on New Interfaces for Musical Expression. pp. 364-369.</li></ul>

	<h2>Play.sound</h2>

	<p>Playsound.space (Stolfi et al. 2018) is a web-based sound search and music creation tool providing access to online audio content from Audio Commons (Freesound). Playsound can be used in a varied range of contexts, from individual soundscape compositions to collaborative live music improvisations with laptop musicians.
		<a href="https://www.audiocommons.org/2018/06/01/nime-2018-playsound.html">The tool was presented at the New Interfaces for Musical Expression conference</a> at Virginia Tech in 2018.</p>

<h3>Example 1 - Demo with laptop trios</h3>

We used Playsound.space in the context of free live music improvisation in small ensembles.
The following video shows laptop trios composed of both non musicians and musicians who were able to play short pieces together after a brief introduction to the tool:</p>

<div class="center-div">
<iframe width="640" height="360" src="https://www.youtube.com/embed/yv8T70rawzs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
</div>

<h3>Example 2 - Crowd Noises by The Puppets</h3>

<p>The following excerpt was produced during an improvisation involving a mixed ensemble of Playsound players and other instrumentalists.
The excerpt was in turn uploaded to Freesound forming an iterative creative loop between sound producers and consumers:</p>

<div class="center-div">
<iframe frameborder="0" scrolling="no" src="https://freesound.org/embed/sound/iframe/434602/simple/large/" width="640" height="240"></iframe>
</div>

<h3>Example 3 - Adaptation of Gertrude Stein's poem Tender Buttons by Ariane Stolfi</h3>

<p>Playsound.space was used by Ariane Stolfi to generate a sonic interpretation of Gertrude Stein's poem Tender Buttons. The performer used excerpts of the poem as the source for semantic searches to obtain Creative Commons audio content from illustrating the poem:</p>

<div class="center-div-audio">
<audio controls>
  <source src="http://finetanks.com/records/playsound/gertrudestein_v1.mp3" type="audio/mpeg">
Your browser does not support the audio element.
</audio>
</div>

<p>The following CC sounds were used in the piece: <a href="http://finetanks.com/records/playsound/gertrudestein_v1.txt">http://finetanks.com/records/playsound/gertrudestein_v1.txt</a>

<h3>References</h3>

<ul><li>Stolfi, A. de Souza, Ceriani, M., Turchet, L. and Barthet, M. (2018). <a href="https://www.researchgate.net/publication/324546442_Playsoundspace_Inclusive_Free_Music_Improvisations_Using_Audio_Commons">Playsound.space: inclusive free music improvisations using Audio Commons</a>. In: Proceedings of the International Conference on New Interfaces for Musical Expression. pp. 228-233.</li></ul>


<h1>Lab Activities</h1>

<p>Several lab activities can be organised to familiarise students with Audio Commons content and tools. We provide several instructions sheets to learn how to use the following tools:</p>

<ul>
	<li><a href="assets/files/MuST-Basics-Routledge.pdf">Audio Commons Sound and Music Search Tool (MuST)</a>: a web interface for accessing Audio Commons sounds and music pieces.</li>
	<li><a href="assets/files/AudioTexture-Basics-Routledge.pdf">AudioGaming’s AudioTexture</a>: a plugin for sound texture synthesis based on local or online audio content from Audio Commons.</li>
	<li><a href="assets/files/Playsound.space-Basics-Routledge.pdf">Playsound.space</a>: a web interface to search for sounds and create music (e.g. live collaborative improvisations, soundscapes) using audio content from Freesound.</li>
</ul>

</main>

</body>
</html>
